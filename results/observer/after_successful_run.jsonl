{"event_type": "after_successful_run", "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job": {"pipe": {"pipe_category": "PipeOperator", "type": "PipeLLM", "code": "detail_pipe_extract", "domain": "pipe_design", "description": "Build a PipeExtractSpec from the signature.", "inputs": {"root": {"plan_draft": {"concept": {"code": "PlanDraft", "domain": "implicit", "description": "implicit.PlanDraft", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}, "pipe_signature": {"concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}, "concept_specs": {"concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}}, "__class__": "InputRequirements", "__module__": "pipelex.core.pipes.input_requirements"}, "output": {"code": "PipeExtractSpec", "domain": "pipe_design", "description": "A structured spec for a PipeExtract.", "structure_class_name": "PipeExtractSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "llm_prompt_spec": {"templating_style": null, "system_prompt_blueprint": null, "prompt_blueprint": {"template": "Design a PipeExtractSpec to extract text from an image or a pdf.\nWhatever it's really going to do has already been decided as part of this plan:\n@plan_draft\n\nYou must pick the relevant concepts for inputs and outputs from the following possibilities:\n@concept_specs\n\n+ you can use the native concepts: Text, Image, PDF, Number, Page\n\nBased on the pipe signature, build the PipeExtractSpec.\n\n@pipe_signature\n", "templating_style": null, "category": "llm_prompt", "extra_context": null, "__class__": "TemplateBlueprint", "__module__": "pipelex.cogt.templating.template_blueprint"}, "user_images": null, "__class__": "LLMPromptBlueprint", "__module__": "pipelex.pipe_operators.llm.llm_prompt_blueprint"}, "llm_choices": {"for_text": "llm_to_engineer", "for_object": null, "__class__": "LLMSettingChoices", "__module__": "pipelex.cogt.llm.llm_setting"}, "structuring_method": null, "output_multiplicity": null, "__class__": "PipeLLM", "__module__": "pipelex.pipe_operators.llm.pipe_llm"}, "working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signature": {"stuff_code": "RXDVk-branch-0", "stuff_name": "pipe_signature", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "Batch result 1 of pipe_specs": {"stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-0", "stuff_name": "Batch result 1 of pipe_specs", "concept": {"code": "PipeExtractSpec", "domain": "pipe_design", "description": "A structured spec for a PipeExtract.", "structure_class_name": "PipeExtractSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"pipe_code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "output": "Page[]", "extract_skill": "extract_text_from_visuals", "page_images": true, "page_image_captions": true, "page_views": null, "__class__": "PipeExtractSpec", "__module__": "pipelex.builder.pipe.pipe_extract_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "Batch result 1 of pipe_specs"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipe_run_params": {"run_mode": "live", "final_stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-0", "is_with_preliminary_text": null, "output_multiplicity": null, "dynamic_output_concept_code": null, "batch_params": {"input_list_stuff_name": "pipe_signatures", "input_item_stuff_name": "pipe_signature", "__class__": "BatchParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "params": {}, "pipe_stack_limit": 20, "pipe_stack": ["pipe_builder", "detail_pipe_spec", "detail_pipe_spec"], "pipe_layers": ["pipe_builder", "detail_pipe_spec"], "__class__": "PipeRunParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "job_metadata": {"job_name": null, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job_ids": ["pipe_builder", "draft_the_plan", "draft_the_concepts", "structure_concepts", "draft_flow", "review_flow", "design_pipe_signatures", "write_bundle_header", "detail_pipe_spec", "detail_pipe_spec", "detail_pipe_extract", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_sequence"], "content_generation_job_id": "make_object_direct", "unit_job_id": "llm_gen_object", "job_category": "llm_job", "started_at": {"datetime": "2025-10-29 19:09:03.868740", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "completed_at": {"datetime": "2025-10-29 19:09:09.596933", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "__class__": "JobMetadata", "__module__": "pipelex.pipeline.job_metadata"}, "output_name": "Batch result 1 of pipe_specs", "__class__": "PipeJob", "__module__": "pipelex.pipe_run.pipe_job"}, "pipe_output": {"working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signature": {"stuff_code": "RXDVk-branch-0", "stuff_name": "pipe_signature", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "Batch result 1 of pipe_specs": {"stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-0", "stuff_name": "Batch result 1 of pipe_specs", "concept": {"code": "PipeExtractSpec", "domain": "pipe_design", "description": "A structured spec for a PipeExtract.", "structure_class_name": "PipeExtractSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"pipe_code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "output": "Page[]", "extract_skill": "extract_text_from_visuals", "page_images": true, "page_image_captions": true, "page_views": null, "__class__": "PipeExtractSpec", "__module__": "pipelex.builder.pipe.pipe_extract_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "Batch result 1 of pipe_specs"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "__class__": "PipeLLMOutput", "__module__": "pipelex.pipe_operators.llm.pipe_llm"}}
{"event_type": "after_successful_run", "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job": {"pipe": {"pipe_category": "PipeOperator", "type": "PipeLLM", "code": "detail_pipe_sequence", "domain": "pipe_design", "description": "Build a PipeSequenceSpec from the signature (children referenced by code).", "inputs": {"root": {"plan_draft": {"concept": {"code": "PlanDraft", "domain": "implicit", "description": "implicit.PlanDraft", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}, "pipe_signature": {"concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}, "concept_specs": {"concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}}, "__class__": "InputRequirements", "__module__": "pipelex.core.pipes.input_requirements"}, "output": {"code": "PipeSequenceSpec", "domain": "pipe_design", "description": "A structured spec for a PipeSequence.", "structure_class_name": "PipeSequenceSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "llm_prompt_spec": {"templating_style": null, "system_prompt_blueprint": null, "prompt_blueprint": {"template": "# Orchestrate a sequence of pipe steps that will run one after the other.\n\n@plan_draft\n\nYou must pick the relevant concepts for inputs and outputs from the following possibilities:\n@concept_specs\n\n+ you can use the native concepts: Text, Image, PDF, Number, Page\n\n@pipe_signature\n\nBased on the pipe signature, build the PipeSequenceSpec.\n\nNote:\n- The output concept of a pipe sequence must always be the same as the output concept of the last pipe in the sequence.\n", "templating_style": null, "category": "llm_prompt", "extra_context": null, "__class__": "TemplateBlueprint", "__module__": "pipelex.cogt.templating.template_blueprint"}, "user_images": null, "__class__": "LLMPromptBlueprint", "__module__": "pipelex.pipe_operators.llm.llm_prompt_blueprint"}, "llm_choices": {"for_text": "llm_to_engineer", "for_object": null, "__class__": "LLMSettingChoices", "__module__": "pipelex.cogt.llm.llm_setting"}, "structuring_method": null, "output_multiplicity": null, "__class__": "PipeLLM", "__module__": "pipelex.pipe_operators.llm.pipe_llm"}, "working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signature": {"stuff_code": "RXDVk-branch-3", "stuff_name": "pipe_signature", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "Batch result 4 of pipe_specs": {"stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-3", "stuff_name": "Batch result 4 of pipe_specs", "concept": {"code": "PipeSequenceSpec", "domain": "pipe_design", "description": "A structured spec for a PipeSequence.", "structure_class_name": "PipeSequenceSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"pipe_code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "output": "SensitivityAssessment", "steps": [{"pipe_code": "extract_image_content", "result": "extracted_pages", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "analyze_image_content", "result": "content_analysis", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "classify_sensitivity", "result": "sensitivity_assessment", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}], "__class__": "PipeSequenceSpec", "__module__": "pipelex.builder.pipe.pipe_sequence_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "Batch result 4 of pipe_specs"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipe_run_params": {"run_mode": "live", "final_stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-3", "is_with_preliminary_text": null, "output_multiplicity": null, "dynamic_output_concept_code": null, "batch_params": {"input_list_stuff_name": "pipe_signatures", "input_item_stuff_name": "pipe_signature", "__class__": "BatchParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "params": {}, "pipe_stack_limit": 20, "pipe_stack": ["pipe_builder", "detail_pipe_spec", "detail_pipe_spec"], "pipe_layers": ["pipe_builder", "detail_pipe_spec"], "__class__": "PipeRunParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "job_metadata": {"job_name": null, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job_ids": ["pipe_builder", "draft_the_plan", "draft_the_concepts", "structure_concepts", "draft_flow", "review_flow", "design_pipe_signatures", "write_bundle_header", "detail_pipe_spec", "detail_pipe_spec", "detail_pipe_extract", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_sequence"], "content_generation_job_id": "make_object_direct", "unit_job_id": "llm_gen_object", "job_category": "llm_job", "started_at": {"datetime": "2025-10-29 19:09:03.868740", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "completed_at": {"datetime": "2025-10-29 19:09:09.613174", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "__class__": "JobMetadata", "__module__": "pipelex.pipeline.job_metadata"}, "output_name": "Batch result 4 of pipe_specs", "__class__": "PipeJob", "__module__": "pipelex.pipe_run.pipe_job"}, "pipe_output": {"working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signature": {"stuff_code": "RXDVk-branch-3", "stuff_name": "pipe_signature", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "Batch result 4 of pipe_specs": {"stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-3", "stuff_name": "Batch result 4 of pipe_specs", "concept": {"code": "PipeSequenceSpec", "domain": "pipe_design", "description": "A structured spec for a PipeSequence.", "structure_class_name": "PipeSequenceSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"pipe_code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "output": "SensitivityAssessment", "steps": [{"pipe_code": "extract_image_content", "result": "extracted_pages", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "analyze_image_content", "result": "content_analysis", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "classify_sensitivity", "result": "sensitivity_assessment", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}], "__class__": "PipeSequenceSpec", "__module__": "pipelex.builder.pipe.pipe_sequence_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "Batch result 4 of pipe_specs"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "__class__": "PipeLLMOutput", "__module__": "pipelex.pipe_operators.llm.pipe_llm"}}
{"event_type": "after_successful_run", "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job": {"pipe": {"pipe_category": "PipeOperator", "type": "PipeLLM", "code": "detail_pipe_llm", "domain": "pipe_design", "description": "Build a PipeLLMSpec from the signature.", "inputs": {"root": {"plan_draft": {"concept": {"code": "PlanDraft", "domain": "implicit", "description": "implicit.PlanDraft", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}, "pipe_signature": {"concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}, "concept_specs": {"concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}}, "__class__": "InputRequirements", "__module__": "pipelex.core.pipes.input_requirements"}, "output": {"code": "PipeLLMSpec", "domain": "pipe_design", "description": "A structured spec for a PipeLLM.", "structure_class_name": "PipeLLMSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "llm_prompt_spec": {"templating_style": null, "system_prompt_blueprint": null, "prompt_blueprint": {"template": "Design a PipeLLMSpec to use an LLM to generate a text, or a structured object using different kinds of inputs.\nWhatever it's really going to do has already been decided as part of this plan:\n@plan_draft\n\nYou must pick the relevant concepts for inputs and outputs from the following possibilities:\n@concept_specs\n\n+ you can use the native concepts: Text, Image, PDF, Number, Page\n\nBased on the pipe signature, build the PipeLLMSpec.\n\n@pipe_signature\n\nNotes: \n- If we are generating a structured concept, indicate it in the system_prompt to clarify the task.\n- But DO NOT detail the structure in any of the user/system prompts: we will add the schema later. So, don't write a bullet-list of all the attributes to determine.\n- If it's to generate free form text, the prompt should indicate to be concise.\n- If it's to generate an image generation prompt, the prompt should indicate to be VERY concise and focus and apply the best practice for image generation.\n", "templating_style": null, "category": "llm_prompt", "extra_context": null, "__class__": "TemplateBlueprint", "__module__": "pipelex.cogt.templating.template_blueprint"}, "user_images": null, "__class__": "LLMPromptBlueprint", "__module__": "pipelex.pipe_operators.llm.llm_prompt_blueprint"}, "llm_choices": {"for_text": "llm_to_engineer", "for_object": null, "__class__": "LLMSettingChoices", "__module__": "pipelex.cogt.llm.llm_setting"}, "structuring_method": null, "output_multiplicity": null, "__class__": "PipeLLM", "__module__": "pipelex.pipe_operators.llm.pipe_llm"}, "working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signature": {"stuff_code": "RXDVk-branch-1", "stuff_name": "pipe_signature", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "Batch result 2 of pipe_specs": {"stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-1", "stuff_name": "Batch result 2 of pipe_specs", "concept": {"code": "PipeLLMSpec", "domain": "pipe_design", "description": "A structured spec for a PipeLLM.", "structure_class_name": "PipeLLMSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"pipe_code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "output": "ContentAnalysis", "llm_skill": "llm_for_visual_analysis", "system_prompt": "You are an expert content analyst. Your task is to analyze visual and textual content to produce a structured ContentAnalysis describing what information is present.", "prompt": "Analyze the following image and its extracted content to identify what information is present.\n\n$image\n\n@extracted_pages\n\nProvide a comprehensive analysis of the content, including:\n- What types of information are visible\n- Key textual elements and their significance\n- Visual elements and their purpose\n- Overall context and subject matter\n\nBe thorough and descriptive in your analysis.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "Batch result 2 of pipe_specs"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipe_run_params": {"run_mode": "live", "final_stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-1", "is_with_preliminary_text": null, "output_multiplicity": null, "dynamic_output_concept_code": null, "batch_params": {"input_list_stuff_name": "pipe_signatures", "input_item_stuff_name": "pipe_signature", "__class__": "BatchParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "params": {}, "pipe_stack_limit": 20, "pipe_stack": ["pipe_builder", "detail_pipe_spec", "detail_pipe_spec"], "pipe_layers": ["pipe_builder", "detail_pipe_spec"], "__class__": "PipeRunParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "job_metadata": {"job_name": null, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job_ids": ["pipe_builder", "draft_the_plan", "draft_the_concepts", "structure_concepts", "draft_flow", "review_flow", "design_pipe_signatures", "write_bundle_header", "detail_pipe_spec", "detail_pipe_spec", "detail_pipe_extract", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_sequence"], "content_generation_job_id": "make_object_direct", "unit_job_id": "llm_gen_object", "job_category": "llm_job", "started_at": {"datetime": "2025-10-29 19:09:03.868740", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "completed_at": {"datetime": "2025-10-29 19:09:11.015513", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "__class__": "JobMetadata", "__module__": "pipelex.pipeline.job_metadata"}, "output_name": "Batch result 2 of pipe_specs", "__class__": "PipeJob", "__module__": "pipelex.pipe_run.pipe_job"}, "pipe_output": {"working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signature": {"stuff_code": "RXDVk-branch-1", "stuff_name": "pipe_signature", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "Batch result 2 of pipe_specs": {"stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-1", "stuff_name": "Batch result 2 of pipe_specs", "concept": {"code": "PipeLLMSpec", "domain": "pipe_design", "description": "A structured spec for a PipeLLM.", "structure_class_name": "PipeLLMSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"pipe_code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "output": "ContentAnalysis", "llm_skill": "llm_for_visual_analysis", "system_prompt": "You are an expert content analyst. Your task is to analyze visual and textual content to produce a structured ContentAnalysis describing what information is present.", "prompt": "Analyze the following image and its extracted content to identify what information is present.\n\n$image\n\n@extracted_pages\n\nProvide a comprehensive analysis of the content, including:\n- What types of information are visible\n- Key textual elements and their significance\n- Visual elements and their purpose\n- Overall context and subject matter\n\nBe thorough and descriptive in your analysis.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "Batch result 2 of pipe_specs"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "__class__": "PipeLLMOutput", "__module__": "pipelex.pipe_operators.llm.pipe_llm"}}
{"event_type": "after_successful_run", "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job": {"pipe": {"pipe_category": "PipeOperator", "type": "PipeLLM", "code": "detail_pipe_llm", "domain": "pipe_design", "description": "Build a PipeLLMSpec from the signature.", "inputs": {"root": {"plan_draft": {"concept": {"code": "PlanDraft", "domain": "implicit", "description": "implicit.PlanDraft", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}, "pipe_signature": {"concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}, "concept_specs": {"concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}}, "__class__": "InputRequirements", "__module__": "pipelex.core.pipes.input_requirements"}, "output": {"code": "PipeLLMSpec", "domain": "pipe_design", "description": "A structured spec for a PipeLLM.", "structure_class_name": "PipeLLMSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "llm_prompt_spec": {"templating_style": null, "system_prompt_blueprint": null, "prompt_blueprint": {"template": "Design a PipeLLMSpec to use an LLM to generate a text, or a structured object using different kinds of inputs.\nWhatever it's really going to do has already been decided as part of this plan:\n@plan_draft\n\nYou must pick the relevant concepts for inputs and outputs from the following possibilities:\n@concept_specs\n\n+ you can use the native concepts: Text, Image, PDF, Number, Page\n\nBased on the pipe signature, build the PipeLLMSpec.\n\n@pipe_signature\n\nNotes: \n- If we are generating a structured concept, indicate it in the system_prompt to clarify the task.\n- But DO NOT detail the structure in any of the user/system prompts: we will add the schema later. So, don't write a bullet-list of all the attributes to determine.\n- If it's to generate free form text, the prompt should indicate to be concise.\n- If it's to generate an image generation prompt, the prompt should indicate to be VERY concise and focus and apply the best practice for image generation.\n", "templating_style": null, "category": "llm_prompt", "extra_context": null, "__class__": "TemplateBlueprint", "__module__": "pipelex.cogt.templating.template_blueprint"}, "user_images": null, "__class__": "LLMPromptBlueprint", "__module__": "pipelex.pipe_operators.llm.llm_prompt_blueprint"}, "llm_choices": {"for_text": "llm_to_engineer", "for_object": null, "__class__": "LLMSettingChoices", "__module__": "pipelex.cogt.llm.llm_setting"}, "structuring_method": null, "output_multiplicity": null, "__class__": "PipeLLM", "__module__": "pipelex.pipe_operators.llm.pipe_llm"}, "working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signature": {"stuff_code": "RXDVk-branch-2", "stuff_name": "pipe_signature", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "Batch result 3 of pipe_specs": {"stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-2", "stuff_name": "Batch result 3 of pipe_specs", "concept": {"code": "PipeLLMSpec", "domain": "pipe_design", "description": "A structured spec for a PipeLLM.", "structure_class_name": "PipeLLMSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"pipe_code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "output": "SensitivityAssessment", "llm_skill": "llm_to_answer_hard_questions", "system_prompt": "You are an expert in information security and data classification. Your task is to evaluate content and determine its sensitivity level based on provided rules. You will generate a structured assessment.", "prompt": "Based on the content analysis and the classification rules provided, determine the sensitivity classification of the content.\n\n@content_analysis\n\n@rules\n\nEvaluate the content against the rules and provide a comprehensive sensitivity assessment.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "Batch result 3 of pipe_specs"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipe_run_params": {"run_mode": "live", "final_stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-2", "is_with_preliminary_text": null, "output_multiplicity": null, "dynamic_output_concept_code": null, "batch_params": {"input_list_stuff_name": "pipe_signatures", "input_item_stuff_name": "pipe_signature", "__class__": "BatchParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "params": {}, "pipe_stack_limit": 20, "pipe_stack": ["pipe_builder", "detail_pipe_spec", "detail_pipe_spec"], "pipe_layers": ["pipe_builder", "detail_pipe_spec"], "__class__": "PipeRunParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "job_metadata": {"job_name": null, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job_ids": ["pipe_builder", "draft_the_plan", "draft_the_concepts", "structure_concepts", "draft_flow", "review_flow", "design_pipe_signatures", "write_bundle_header", "detail_pipe_spec", "detail_pipe_spec", "detail_pipe_extract", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_sequence"], "content_generation_job_id": "make_object_direct", "unit_job_id": "llm_gen_object", "job_category": "llm_job", "started_at": {"datetime": "2025-10-29 19:09:03.868740", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "completed_at": {"datetime": "2025-10-29 19:09:11.712033", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "__class__": "JobMetadata", "__module__": "pipelex.pipeline.job_metadata"}, "output_name": "Batch result 3 of pipe_specs", "__class__": "PipeJob", "__module__": "pipelex.pipe_run.pipe_job"}, "pipe_output": {"working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signature": {"stuff_code": "RXDVk-branch-2", "stuff_name": "pipe_signature", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "Batch result 3 of pipe_specs": {"stuff_code": "ckWUhtixJpzFmcKuTPwNy5-branch-2", "stuff_name": "Batch result 3 of pipe_specs", "concept": {"code": "PipeLLMSpec", "domain": "pipe_design", "description": "A structured spec for a PipeLLM.", "structure_class_name": "PipeLLMSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"pipe_code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "output": "SensitivityAssessment", "llm_skill": "llm_to_answer_hard_questions", "system_prompt": "You are an expert in information security and data classification. Your task is to evaluate content and determine its sensitivity level based on provided rules. You will generate a structured assessment.", "prompt": "Based on the content analysis and the classification rules provided, determine the sensitivity classification of the content.\n\n@content_analysis\n\n@rules\n\nEvaluate the content against the rules and provide a comprehensive sensitivity assessment.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "Batch result 3 of pipe_specs"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "__class__": "PipeLLMOutput", "__module__": "pipelex.pipe_operators.llm.pipe_llm"}}
{"event_type": "after_successful_run", "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job": {"pipe": {"pipe_category": "PipeController", "type": "PipeSequence", "code": "pipe_builder", "domain": "builder", "description": "This pipe is going to be the entry point for the builder. It will take a UserBrief and return a PipelexBundleSpec.", "inputs": {"root": {"brief": {"concept": {"code": "UserBrief", "domain": "builder", "description": "A short, natural-language description of what the user wants.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "multiplicity": null, "__class__": "InputRequirement", "__module__": "pipelex.core.pipes.input_requirements"}}, "__class__": "InputRequirements", "__module__": "pipelex.core.pipes.input_requirements"}, "output": {"code": "PipelexBundleSpec", "domain": "builder", "description": "A Pipelex bundle spec.", "structure_class_name": "PipelexBundleSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "sequential_sub_pipes": [{"pipe_code": "draft_the_plan", "output_name": "plan_draft", "output_multiplicity": null, "batch_params": null, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}, {"pipe_code": "draft_the_concepts", "output_name": "concept_drafts", "output_multiplicity": null, "batch_params": null, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}, {"pipe_code": "structure_concepts", "output_name": "concept_specs", "output_multiplicity": null, "batch_params": null, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}, {"pipe_code": "draft_flow", "output_name": "flow_draft", "output_multiplicity": null, "batch_params": null, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}, {"pipe_code": "review_flow", "output_name": "prepared_flow", "output_multiplicity": null, "batch_params": null, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}, {"pipe_code": "design_pipe_signatures", "output_name": "pipe_signatures", "output_multiplicity": null, "batch_params": null, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}, {"pipe_code": "write_bundle_header", "output_name": "bundle_header_spec", "output_multiplicity": null, "batch_params": null, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}, {"pipe_code": "detail_pipe_spec", "output_name": "pipe_specs", "output_multiplicity": null, "batch_params": {"input_list_stuff_name": "pipe_signatures", "input_item_stuff_name": "pipe_signature", "__class__": "BatchParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}, {"pipe_code": "assemble_pipelex_bundle_spec", "output_name": "pipelex_bundle_spec", "output_multiplicity": null, "batch_params": null, "concept_codes_from_the_same_domain": ["UserBrief", "PlanDraft", "ConceptDrafts", "PipelexBundleSpec", "BundleHeaderSpec", "FlowDraft"], "__class__": "SubPipe", "__module__": "pipelex.pipe_controllers.sub_pipe"}], "__class__": "PipeSequence", "__module__": "pipelex.pipe_controllers.sequence.pipe_sequence"}, "working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_specs": {"stuff_code": "635t5", "stuff_name": "pipe_specs", "concept": {"code": "Anything", "domain": "native", "description": "Anything", "structure_class_name": "AnythingContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"pipe_code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "output": "Page[]", "extract_skill": "extract_text_from_visuals", "page_images": true, "page_image_captions": true, "page_views": null, "__class__": "PipeExtractSpec", "__module__": "pipelex.builder.pipe.pipe_extract_spec"}, {"pipe_code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "output": "ContentAnalysis", "llm_skill": "llm_for_visual_analysis", "system_prompt": "You are an expert content analyst. Your task is to analyze visual and textual content to produce a structured ContentAnalysis describing what information is present.", "prompt": "Analyze the following image and its extracted content to identify what information is present.\n\n$image\n\n@extracted_pages\n\nProvide a comprehensive analysis of the content, including:\n- What types of information are visible\n- Key textual elements and their significance\n- Visual elements and their purpose\n- Overall context and subject matter\n\nBe thorough and descriptive in your analysis.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, {"pipe_code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "output": "SensitivityAssessment", "llm_skill": "llm_to_answer_hard_questions", "system_prompt": "You are an expert in information security and data classification. Your task is to evaluate content and determine its sensitivity level based on provided rules. You will generate a structured assessment.", "prompt": "Based on the content analysis and the classification rules provided, determine the sensitivity classification of the content.\n\n@content_analysis\n\n@rules\n\nEvaluate the content against the rules and provide a comprehensive sensitivity assessment.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, {"pipe_code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "output": "SensitivityAssessment", "steps": [{"pipe_code": "extract_image_content", "result": "extracted_pages", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "analyze_image_content", "result": "content_analysis", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "classify_sensitivity", "result": "sensitivity_assessment", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}], "__class__": "PipeSequenceSpec", "__module__": "pipelex.builder.pipe.pipe_sequence_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipelex_bundle_spec": {"stuff_code": "HwAUb", "stuff_name": "pipelex_bundle_spec", "concept": {"code": "PipelexBundleSpec", "domain": "builder", "description": "A Pipelex bundle spec.", "structure_class_name": "PipelexBundleSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "concept": {"SensitivityAssessment": {"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "ContentAnalysis": {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "pipe": {"extract_image_content": {"pipe_code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "output": "Page[]", "extract_skill": "extract_text_from_visuals", "page_images": true, "page_image_captions": true, "page_views": null, "__class__": "PipeExtractSpec", "__module__": "pipelex.builder.pipe.pipe_extract_spec"}, "analyze_image_content": {"pipe_code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "output": "ContentAnalysis", "llm_skill": "llm_for_visual_analysis", "system_prompt": "You are an expert content analyst. Your task is to analyze visual and textual content to produce a structured ContentAnalysis describing what information is present.", "prompt": "Analyze the following image and its extracted content to identify what information is present.\n\n$image\n\n@extracted_pages\n\nProvide a comprehensive analysis of the content, including:\n- What types of information are visible\n- Key textual elements and their significance\n- Visual elements and their purpose\n- Overall context and subject matter\n\nBe thorough and descriptive in your analysis.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, "classify_sensitivity": {"pipe_code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "output": "SensitivityAssessment", "llm_skill": "llm_to_answer_hard_questions", "system_prompt": "You are an expert in information security and data classification. Your task is to evaluate content and determine its sensitivity level based on provided rules. You will generate a structured assessment.", "prompt": "Based on the content analysis and the classification rules provided, determine the sensitivity classification of the content.\n\n@content_analysis\n\n@rules\n\nEvaluate the content against the rules and provide a comprehensive sensitivity assessment.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, "assess_image_sensitivity": {"pipe_code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "output": "SensitivityAssessment", "steps": [{"pipe_code": "extract_image_content", "result": "extracted_pages", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "analyze_image_content", "result": "content_analysis", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "classify_sensitivity", "result": "sensitivity_assessment", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}], "__class__": "PipeSequenceSpec", "__module__": "pipelex.builder.pipe.pipe_sequence_spec"}}, "__class__": "PipelexBundleSpec", "__module__": "pipelex.builder.bundle_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "pipelex_bundle_spec"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipe_run_params": {"run_mode": "live", "final_stuff_code": null, "is_with_preliminary_text": null, "output_multiplicity": null, "dynamic_output_concept_code": null, "batch_params": null, "params": {}, "pipe_stack_limit": 20, "pipe_stack": [], "pipe_layers": ["pipe_builder", "detail_pipe_spec"], "__class__": "PipeRunParams", "__module__": "pipelex.pipe_run.pipe_run_params"}, "job_metadata": {"job_name": null, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "pipe_job_ids": ["pipe_builder", "draft_the_plan", "draft_the_concepts", "structure_concepts", "draft_flow", "review_flow", "design_pipe_signatures", "write_bundle_header", "detail_pipe_spec", "detail_pipe_spec", "detail_pipe_extract", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_llm", "detail_pipe_spec", "detail_pipe_sequence", "assemble_pipelex_bundle_spec"], "content_generation_job_id": "make_object_direct", "unit_job_id": "llm_gen_object", "job_category": "llm_job", "started_at": {"datetime": "2025-10-29 19:09:11.729733", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "completed_at": {"datetime": "2025-10-29 19:09:11.712033", "tzinfo": null, "__class__": "datetime", "__module__": "datetime"}, "__class__": "JobMetadata", "__module__": "pipelex.pipeline.job_metadata"}, "output_name": null, "__class__": "PipeJob", "__module__": "pipelex.pipe_run.pipe_job"}, "pipe_output": {"working_memory": {"root": {"brief": {"stuff_code": "KA4Uo", "stuff_name": "brief", "concept": {"code": "Text", "domain": "native", "description": "A text", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "take a image and rules(text) as input, analyse the content of the image and compare with rules tell if its sensitive information, (public, internal, confidential, restrictive) give rating out of 10 sensitivity and should it be deleted and when should it be delted in strcutured form json", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "plan_draft": {"stuff_code": "KkmZE", "stuff_name": "plan_draft", "concept": {"code": "PlanDraft", "domain": "builder", "description": "Natural-language pipeline plan text describing sequences, inputs, outputs.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Pipeline Plan\n\n## Initial Inputs\n- image\n- rules\n\n## Pipeline Structure\n\n### SEQUENCE\nExecutes the analysis and classification workflow.\n\n**Pipe 1: EXTRACT**\nExtracts text and visual content from the image for analysis.\n- Inputs: image\n- Output: extracted_pages\n\n**Pipe 2: LLM (analyze_image_content)**\nAnalyzes the visual and textual content of the image to identify what information is present.\n- Inputs: image, extracted_pages\n- Output: content_analysis\n\n**Pipe 3: LLM (classify_sensitivity)**\nCompares the content analysis against the rules to determine sensitivity classification, rating, and deletion recommendation. Uses structured output (JSON).\n- Inputs: content_analysis, rules\n- Output: sensitivity_assessment\n\nStructured output format for sensitivity_assessment:\n- classification (public/internal/confidential/restrictive)\n- sensitivity_rating (0-10)\n- should_be_deleted (boolean)\n- deletion_date (ISO date string or null)\n- reasoning (text explanation)", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_drafts": {"stuff_code": "gGnGD", "stuff_name": "concept_drafts", "concept": {"code": "ConceptDrafts", "domain": "builder", "description": "Textual draft of the concepts to create.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "### Concept SensitivityAssessment\n\nStructured evaluation of information sensitivity based on predefined rules.\n\n- classification\n  - description: The sensitivity level of the content\n  - type: text\n  - required: true\n\n- sensitivity_rating\n  - description: Numerical rating of sensitivity from 0 to 10\n  - type: integer\n  - required: true\n\n- should_be_deleted\n  - description: Whether the content should be deleted\n  - type: boolean\n  - required: true\n\n- deletion_date\n  - description: The date when the content should be deleted in ISO format\n  - type: date\n\n- reasoning\n  - description: Explanation for the sensitivity classification and deletion recommendation\n  - type: text\n  - required: true\n\n### Concept ContentAnalysis\n\nDescription of the information and elements identified within visual or textual content.\n\nrefines: Text", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "concept_specs": {"stuff_code": "VLUZc", "stuff_name": "concept_specs", "concept": {"code": "ConceptSpec", "domain": "concept", "description": "A specification for a concept including its code, description, and a structure draft as plain text.", "structure_class_name": "ConceptSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "flow_draft": {"stuff_code": "c8NYF", "stuff_name": "flow_draft", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "prepared_flow": {"stuff_code": "VooQB", "stuff_name": "prepared_flow", "concept": {"code": "FlowDraft", "domain": "builder", "description": "Draft of the flow of the pipeline.", "structure_class_name": "TextContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"text": "Let me narrate the flow step by step:\n\n## Flow Narration\n\n**Beginning:** The pipeline starts with two inputs - an `image` to be analyzed and `rules` (text) that define sensitivity criteria.\n\n**Step 1 (extract_image_content):** The image is processed through a PipeExtract to extract text and visual elements, producing `extracted_pages` (an array of Page objects).\n\n**Step 2 (analyze_image_content):** Both the original `image` and the `extracted_pages` are fed into a PipeLLM to analyze and identify what information is present, producing `content_analysis` (a ContentAnalysis object).\n\n**Step 3 (classify_sensitivity):** The `content_analysis` and the original `rules` are compared by a PipeLLM to determine the sensitivity classification (public/internal/confidential/restrictive), a rating out of 10, and deletion recommendations, producing the final `sensitivity_assessment` (a SensitivityAssessment object).\n\n**End:** The main pipe returns the `sensitivity_assessment` as structured JSON output.\n\n## Consistency Check\n\n\u2705 **Main pipe exists and is appropriate:** Yes, `assess_image_sensitivity` orchestrates the complete workflow to answer the brief.\n\n\u2705 **Main pipe inputs are consistent with brief:** The main pipe takes `image` and `rules` as inputs, which matches the brief exactly. Neither of these are generated by the flow itself.\n\n\u2705 **No batching issues:** Neither input is a list/multiple, so no batching concerns.\n\n\u2705 **Variable names and flow:** All variables are properly defined and flow logically through the pipeline.\n\n\u2705 **No PipeImgGen issues:** There is no PipeImgGen in this flow.\n\n\u2705 **Output matches brief requirements:** The final output is a structured SensitivityAssessment that should contain classification, rating, and deletion recommendation in JSON format.\n\n---\n\n**The flow has been checked and is consistent:**\n\n```\n# Structured Pipeline Flow\n\n## Pipeline Initial Inputs\n- `image` (Image)\n- `rules` (Text)\n\n---\n\n## Pipe Definitions\n\n### Pipe 1: extract_image_content\n**Type:** PipeExtract\n\n**Description:** Extracts text and visual elements from the input image for content analysis.\n\n**Inputs:**\n- `image`: Image\n\n**Result:** `extracted_pages`\n\n**Output:** Page[]\n\n---\n\n### Pipe 2: analyze_image_content\n**Type:** PipeLLM\n\n**Description:** Analyzes the extracted content and visual elements to identify what information is present in the image.\n\n**Inputs:**\n- `image`: Image\n- `extracted_pages`: Page[]\n\n**Result:** `content_analysis`\n\n**Output:** ContentAnalysis\n\n---\n\n### Pipe 3: classify_sensitivity\n**Type:** PipeLLM\n\n**Description:** Compares the content analysis against the provided rules to determine sensitivity classification, rating, and deletion recommendation with structured JSON output.\n\n**Inputs:**\n- `content_analysis`: ContentAnalysis\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n---\n\n### Main Pipe: assess_image_sensitivity\n**Type:** PipeSequence\n\n**Description:** # MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules.\n\n**Inputs:**\n- `image`: Image\n- `rules`: Text\n\n**Result:** `sensitivity_assessment`\n\n**Output:** SensitivityAssessment\n\n**Steps:**\n1. `pipe`: extract_image_content, `result`: extracted_pages\n2. `pipe`: analyze_image_content, `result`: content_analysis\n3. `pipe`: classify_sensitivity, `result`: sensitivity_assessment\n\n---\n\n## Variables Recap\n\n| Variable Name | Description | Concept | Multiplicity | Refines |\n|---------------|-------------|---------|--------------|---------|\n| `image` | Input image to analyze | Image | Single | Native |\n| `rules` | Sensitivity classification rules | Text | Single | Native |\n| `extracted_pages` | Extracted text and visual elements | Page | Multiple [] | Native |\n| `content_analysis` | Description of identified information | ContentAnalysis | Single | Text |\n| `sensitivity_assessment` | Final structured sensitivity evaluation | SensitivityAssessment | Single | - |\n```", "__class__": "TextContent", "__module__": "pipelex.core.stuffs.text_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_signatures": {"stuff_code": "RXDVk", "stuff_name": "pipe_signatures", "concept": {"code": "PipeSignature", "domain": "pipe_design", "description": "A pipe contract which says what the pipe does, not how it does it: code (the pipe code in snake_case), type, description, inputs, output.", "structure_class_name": "PipeSignature", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "result": "extracted_pages", "output": "Page[]", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "result": "content_analysis", "output": "ContentAnalysis", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": [], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}, {"code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "result": "sensitivity_assessment", "output": "SensitivityAssessment", "pipe_dependencies": ["extract_image_content", "analyze_image_content", "classify_sensitivity"], "__class__": "PipeSignature", "__module__": "pipelex.builder.pipe.pipe_signature"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "bundle_header_spec": {"stuff_code": "KFnTE", "stuff_name": "bundle_header_spec", "concept": {"code": "BundleHeaderSpec", "domain": "builder", "description": "A domain information object.", "structure_class_name": "BundleHeaderSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "__class__": "BundleHeaderSpec", "__module__": "pipelex.builder.bundle_header_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipe_specs": {"stuff_code": "635t5", "stuff_name": "pipe_specs", "concept": {"code": "Anything", "domain": "native", "description": "Anything", "structure_class_name": "AnythingContent", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"items": [{"pipe_code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "output": "Page[]", "extract_skill": "extract_text_from_visuals", "page_images": true, "page_image_captions": true, "page_views": null, "__class__": "PipeExtractSpec", "__module__": "pipelex.builder.pipe.pipe_extract_spec"}, {"pipe_code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "output": "ContentAnalysis", "llm_skill": "llm_for_visual_analysis", "system_prompt": "You are an expert content analyst. Your task is to analyze visual and textual content to produce a structured ContentAnalysis describing what information is present.", "prompt": "Analyze the following image and its extracted content to identify what information is present.\n\n$image\n\n@extracted_pages\n\nProvide a comprehensive analysis of the content, including:\n- What types of information are visible\n- Key textual elements and their significance\n- Visual elements and their purpose\n- Overall context and subject matter\n\nBe thorough and descriptive in your analysis.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, {"pipe_code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "output": "SensitivityAssessment", "llm_skill": "llm_to_answer_hard_questions", "system_prompt": "You are an expert in information security and data classification. Your task is to evaluate content and determine its sensitivity level based on provided rules. You will generate a structured assessment.", "prompt": "Based on the content analysis and the classification rules provided, determine the sensitivity classification of the content.\n\n@content_analysis\n\n@rules\n\nEvaluate the content against the rules and provide a comprehensive sensitivity assessment.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, {"pipe_code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "output": "SensitivityAssessment", "steps": [{"pipe_code": "extract_image_content", "result": "extracted_pages", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "analyze_image_content", "result": "content_analysis", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "classify_sensitivity", "result": "sensitivity_assessment", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}], "__class__": "PipeSequenceSpec", "__module__": "pipelex.builder.pipe.pipe_sequence_spec"}], "__class__": "ListContent", "__module__": "pipelex.core.stuffs.list_content"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}, "pipelex_bundle_spec": {"stuff_code": "HwAUb", "stuff_name": "pipelex_bundle_spec", "concept": {"code": "PipelexBundleSpec", "domain": "builder", "description": "A Pipelex bundle spec.", "structure_class_name": "PipelexBundleSpec", "refines": null, "__class__": "Concept", "__module__": "pipelex.core.concepts.concept"}, "content": {"domain": "image_sensitivity_assessment", "description": "Assessing image content sensitivity against rules to determine classification, rating, and deletion recommendations.", "system_prompt": null, "main_pipe": "assess_image_sensitivity", "concept": {"SensitivityAssessment": {"the_concept_code": "SensitivityAssessment", "description": "Structured evaluation of information sensitivity based on predefined rules.", "structure": {"classification": {"the_field_name": "classification", "description": "The sensitivity level of the content", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "sensitivity_rating": {"the_field_name": "sensitivity_rating", "description": "Numerical rating of sensitivity from 0 to 10", "type": "integer", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "should_be_deleted": {"the_field_name": "should_be_deleted", "description": "Whether the content should be deleted", "type": "boolean", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "deletion_date": {"the_field_name": "deletion_date", "description": "The date when the content should be deleted in ISO format", "type": "date", "required": null, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "reasoning": {"the_field_name": "reasoning", "description": "Explanation for the sensitivity classification and deletion recommendation", "type": "text", "required": true, "default_value": null, "__class__": "ConceptStructureSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "refines": null, "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}, "ContentAnalysis": {"the_concept_code": "ContentAnalysis", "description": "Description of the information and elements identified within visual or textual content.", "structure": null, "refines": "Text", "__class__": "ConceptSpec", "__module__": "pipelex.builder.concept.concept_spec"}}, "pipe": {"extract_image_content": {"pipe_code": "extract_image_content", "type": "PipeExtract", "pipe_category": "PipeOperator", "description": "Extracts text and visual elements from the input image for content analysis.", "inputs": {"image": "Image"}, "output": "Page[]", "extract_skill": "extract_text_from_visuals", "page_images": true, "page_image_captions": true, "page_views": null, "__class__": "PipeExtractSpec", "__module__": "pipelex.builder.pipe.pipe_extract_spec"}, "analyze_image_content": {"pipe_code": "analyze_image_content", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Analyzes the extracted content and visual elements to identify what information is present in the image.", "inputs": {"image": "Image", "extracted_pages": "Page[]"}, "output": "ContentAnalysis", "llm_skill": "llm_for_visual_analysis", "system_prompt": "You are an expert content analyst. Your task is to analyze visual and textual content to produce a structured ContentAnalysis describing what information is present.", "prompt": "Analyze the following image and its extracted content to identify what information is present.\n\n$image\n\n@extracted_pages\n\nProvide a comprehensive analysis of the content, including:\n- What types of information are visible\n- Key textual elements and their significance\n- Visual elements and their purpose\n- Overall context and subject matter\n\nBe thorough and descriptive in your analysis.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, "classify_sensitivity": {"pipe_code": "classify_sensitivity", "type": "PipeLLM", "pipe_category": "PipeOperator", "description": "Compares the content analysis against the provided rules to determine sensitivity classification (public, internal, confidential, restrictive), rating out of 10, and deletion recommendation with structured JSON output.", "inputs": {"content_analysis": "ContentAnalysis", "rules": "Text"}, "output": "SensitivityAssessment", "llm_skill": "llm_to_answer_hard_questions", "system_prompt": "You are an expert in information security and data classification. Your task is to evaluate content and determine its sensitivity level based on provided rules. You will generate a structured assessment.", "prompt": "Based on the content analysis and the classification rules provided, determine the sensitivity classification of the content.\n\n@content_analysis\n\n@rules\n\nEvaluate the content against the rules and provide a comprehensive sensitivity assessment.", "__class__": "PipeLLMSpec", "__module__": "pipelex.builder.pipe.pipe_llm_spec"}, "assess_image_sensitivity": {"pipe_code": "assess_image_sensitivity", "type": "PipeSequence", "pipe_category": "PipeController", "description": "MAIN PIPE - Orchestrates the complete workflow to assess image sensitivity based on rules, analyzing content and comparing against sensitivity criteria to produce a structured assessment with classification, rating, and deletion recommendations.", "inputs": {"image": "Image", "rules": "Text"}, "output": "SensitivityAssessment", "steps": [{"pipe_code": "extract_image_content", "result": "extracted_pages", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "analyze_image_content", "result": "content_analysis", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}, {"pipe_code": "classify_sensitivity", "result": "sensitivity_assessment", "__class__": "SubPipeSpec", "__module__": "pipelex.builder.pipe.sub_pipe_spec"}], "__class__": "PipeSequenceSpec", "__module__": "pipelex.builder.pipe.pipe_sequence_spec"}}, "__class__": "PipelexBundleSpec", "__module__": "pipelex.builder.bundle_spec"}, "__class__": "Stuff", "__module__": "pipelex.core.stuffs.stuff"}}, "aliases": {"main_stuff": "pipelex_bundle_spec"}, "__class__": "WorkingMemory", "__module__": "pipelex.core.memory.working_memory"}, "pipeline_run_id": "DKJvMuybS9FDVPaoWYtEPo", "__class__": "PipeOutput", "__module__": "pipelex.core.pipes.pipe_output"}}
